{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utiliser des mod√®les\n",
    "\n",
    "De plus en plus de mod√®les pr√©entrain√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charger les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/dataframe.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Une approche int√©gr√©e avec SpaCy\n",
    "\n",
    "- `SpaCy` a des mod√®les entra√Æn√©s pour les NER\n",
    "- Par exemple pour le fran√ßais, [plusieurs mod√®les sont disponibles](https://spacy.io/models/fr)\n",
    "    - Avec des architectures diff√©rentes\n",
    "- Une biblioth√®que qui donne un framework commun.\n",
    "\n",
    "::: {.callout-note appearance=\"simple\" title=\"NER\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une √©tape : t√©l√©charger des mod√®les\n",
    "\n",
    "https://github.com/explosion/spacy-models/releases/tag/fr_core_news_md-3.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0, \"texte\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "doc = nlp(df.loc[0, \"texte\"])\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipuler les repr√©sentations du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc[0:10]:\n",
    "    print(f\"{token.text:<15} | lemma: {token.lemma_} | POS: {token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents[0:10]:\n",
    "    print(f\"{ent.text:<25} | label: {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc[0:100], style=\"dep\", jupyter=True, options={\"compact\": True})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un usage : r√©cup√©rer uniquement les verbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verbs(doc):\n",
    "    \"\"\"\n",
    "    Get the verbs from a spacy doc\n",
    "    \"\"\"\n",
    "    return [token.lemma_ for token in doc if token.pos_ == \"VERB\"]\n",
    "\n",
    "tmp =  df[\"texte\"][0:100].apply(lambda x: get_verbs(nlp(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter([j for i in tmp for j in i if j]).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un autre usage : nettoyer des textes\n",
    "\n",
    "Plut√¥t que faire de la tokenisation brutale, nettoyer en prenant uniquement les lemmes puis faire un TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aller utiliser d'autres mod√®les sur huggingface\n",
    "\n",
    "Commen√ßons par faire un tour sur Huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pr√©dire des entit√©s nomm√©es\n",
    "\n",
    "Utilsons le mod√®le [GliNER disponible sur HuggingFace](https://github.com/urchade/GLiNER)\n",
    "\n",
    "Ou sa version plus r√©cente [GliNer](https://huggingface.co/knowledgator/gliner-multitask-large-v0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"knowledgator/gliner-multitask-large-v0.5\")\n",
    "\n",
    "text = df.loc[0, \"texte\"]\n",
    "\n",
    "labels = [\"politicien ou politicienne\"]\n",
    "\n",
    "entities = model.predict_entities(text, labels)\n",
    "\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De nombreux mod√®les et la possibilit√© d'en entra√Æner\n",
    "\n",
    "PAr exemple : https://huggingface.co/NousResearch/Minos-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse de sentiment\n",
    "\n",
    "Une question : **quelles sont les prises de paroles les plus n√©gatives ?**\n",
    "\n",
    "- Embarras du choix\n",
    "    - Par ex : [üöÄ distilbert-based Multilingual Sentiment Classification Model\n",
    "](https://huggingface.co/tabularisai/multilingual-sentiment-analysis)\n",
    "- Comprendre le mod√®le / ce qu'il fait\n",
    "- Importance d'√©valuer son r√©sultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utiliser des mod√®les ext√©rieurs\n",
    "\n",
    "Il faut un endpoint :\n",
    "\n",
    "- Ollama\n",
    "- OpenAI\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# D√©finir la prompt de classification\n",
    "prompt = \"\"\"Est-ce que ce texte est positif ou n√©gatif : Je ne comprends rien au NLP\"\"\"\n",
    "\n",
    "# Envoi de la requ√™te √† Ollama\n",
    "response = requests.post(\n",
    "    'https://llm-tools-alpha.huma-num.fr/ES_hpEC1VnleR_8C52IbSxHF/api/generate',\n",
    "    json={\n",
    "        'model': 'llama3.3',\n",
    "        'prompt': prompt,\n",
    "        'stream': False  # stream=False pour avoir une r√©ponse simple\n",
    "    }\n",
    ")\n",
    "\n",
    "# Traitement de la r√©ponse\n",
    "result = response.json()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
