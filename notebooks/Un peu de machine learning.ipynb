{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De la représentation au machine learning\n",
    "\n",
    "Un exemple parmi d'autres\n",
    "\n",
    "- une représentation numérique\n",
    "- un modèle (supevisé ou non supervisé) en fonction de la tâche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/dataframe.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculer une représentation tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['texte'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faire une classification hiérarchique ascendante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(tfidf_matrix.toarray(), method='ward')  #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire une représentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "dendrogram(Z, orientation='right')\n",
    "plt.title(\"Classification Hiérarchique Ascendante (CHA)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quels sont les questions les plus fréquentes ? Sont-elles posées sur les mêmes périodes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=12,  linkage='ward')\n",
    "labels = cluster.fit_predict(tfidf_matrix.toarray())\n",
    "df['cluster'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire une représentation temporelle des clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "df['date_val'] = pd.to_datetime(df['date'], format='mixed')\n",
    "df.set_index('date_val').resample('ME')[\"cluster\"].value_counts().unstack().plot(ax = ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quel est le contenu des clusters ?\n",
    "\n",
    "Comment faire pour faire un résumé des clusters ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une réponse : prendre la liste des mots les plus spécifiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w[df[\"cluster\"] == 4].max().sort_values()[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut améliorer :\n",
    "\n",
    "- le choix des clusters\n",
    "- la manière de résumer un cluster\n",
    "- la représentation des textes\n",
    "- le découpage des textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D'autres embeddings\n",
    "\n",
    "Par exemple, les modèles fasttext https://fasttext.cc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger ce modèle depuis https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "model = load_facebook_vectors('../../../../../../Documents/models/cc.fr.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(words):\n",
    "    word_vecs = [model[word] for word in words if word in model]\n",
    "    return np.mean(word_vecs, axis=0) if word_vecs else np.zeros(model.vector_size)\n",
    "\n",
    "# Matrice d'embeddings\n",
    "X_embed = np.array([document_vector(doc) for doc in documents])\n",
    "print(X_embed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou bien utiliser sbert https://sbert.net/ \n",
    "\n",
    "On voit apparaître de plus en plus de modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite la logique est la même..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empiler les traitements : BERTOPIC\n",
    "\n",
    "Utiliser les différentes couches ensemble pour faire de la détection de thématiques : pipelines comme [BERTOPIC](https://maartengr.github.io/BERTopic/index.html)\n",
    "\n",
    "![](../slides/img/bertopic.png){fig-align=\"center\"}\n",
    "\n",
    "[Faisons un test sur les données](https://maartengr.github.io/BERTopic/getting_started/quickstart/quickstart.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import bertopic\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "french_stopwords = list(set(stopwords.words(\"french\")))\n",
    "vectorizer_model = CountVectorizer(stop_words=french_stopwords)\n",
    "topic_model = bertopic.BERTopic(            language=\"french\", \n",
    "            vectorizer_model=vectorizer_model)\n",
    "topics, probs = topic_model.fit_transform(df['texte'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
